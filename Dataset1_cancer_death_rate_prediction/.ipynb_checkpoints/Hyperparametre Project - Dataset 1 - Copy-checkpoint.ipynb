{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:Blue\">Hyperparametre Project - Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "The goal of this project is to predict Cancer Mortality Rates for US Counties using multiple regression algorithms. To predict the Cancer Mortality Rates first we we will find the predictors (i.e _indipendant variables_) with strong relation to our target variable '_TARGET_deathRate_'. To achieve better results we will be cleaning data by removing extream outliers and normalizing it. We will be using varios regression algorithms like linear Regression, Logistic regression, StepWise Regression and regularization using either Ridge regression (i.e _L2 regularization_) or Lasso regression (i.e _L1 regularization_). To make prediction more accurate we will create multiple models and compare the accuracy/outputs of models to get better predictions. Further we will be cross validating output of each model using varios methods like K-Fold, cross_val_score from sklearn.\n",
    "\n",
    "### Data Dictionary\n",
    "***TARGET_deathRate*** : Dependent variable. Mean per capita (100,000) cancer mortalities(a) <br />\n",
    "***avgAnnCount*** : Mean number of reported cases of cancer diagnosed annually(a) <br />\n",
    "***avgDeathsPerYear*** : Mean number of reported mortalities due to cancer(a) <br />\n",
    "***incidenceRate*** : Mean per capita (100,000) cancer diagoses(a) <br />\n",
    "***medianIncome*** : Median income per county (b) <br />\n",
    "***popEst2015*** : Population of county (b) <br />\n",
    "***povertyPercent*** : Percent of populace in poverty (b) <br />\n",
    "***studyPerCap*** : Per capita number of cancer-related clinical trials per county (a) <br />\n",
    "***binnedInc*** : Median income per capita binned by decile (b) <br />\n",
    "***MedianAge*** : Median age of county residents (b) <br />\n",
    "***MedianAgeMale*** : Median age of male county residents (b) <br />\n",
    "***MedianAgeFemale*** : Median age of female county residents (b) <br />\n",
    "***Geography*** : County name (b) <br />\n",
    "***AvgHouseholdSize*** : Mean household size of county (b) <br />\n",
    "***PercentMarried*** : Percent of county residents who are married (b) <br />\n",
    "***PctNoHS18_24*** : Percent of county residents ages 18-24 highest education attained: less than high school (b) <br />\n",
    "***PctHS18_24*** : Percent of county residents ages 18-24 highest education attained: high school diploma (b) <br />\n",
    "***PctSomeCol18_24*** : Percent of county residents ages 18-24 highest education attained: some college (b) <br />\n",
    "***PctBachDeg18_24*** : Percent of county residents ages 18-24 highest education attained: bachelor's degree (b) <br />\n",
    "***PctHS25_Over*** : Percent of county residents ages 25 and over highest education attained: high school diploma (b) <br />\n",
    "***PctBachDeg25_Over*** : Percent of county residents ages 25 and over highest education attained: bachelor's degree (b) <br />\n",
    "***PctEmployed16_Over*** : Percent of county residents ages 16 and over employed (b) <br />\n",
    "***PctUnemployed16_Over*** : Percent of county residents ages 16 and over unemployed (b) <br />\n",
    "***PctPrivateCoverage*** : Percent of county residents with private health coverage (b) <br />\n",
    "***PctPrivateCoverageAlone*** : Percent of county residents with private health coverage alone (no public assistance) (b) <br />\n",
    "***PctEmpPrivCoverage*** : Percent of county residents with employee-provided private health coverage (b) <br />\n",
    "***PctPublicCoverage*** : Percent of county residents with government-provided health coverage (b) <br />\n",
    "***PctPubliceCoverageAlone*** : Percent of county residents with government-provided health coverage alone (b) <br />\n",
    "***PctWhite*** : Percent of county residents who identify as White (b) <br />\n",
    "***PctBlack*** : Percent of county residents who identify as Black (b) <br />\n",
    "***PctAsian*** : Percent of county residents who identify as Asian (b) <br />\n",
    "***PctOtherRace*** : Percent of county residents who identify in a category which is not White, Black, or Asian (b) <br />\n",
    "***PctMarriedHouseholds*** : Percent of married households (b) <br />\n",
    "***BirthRate*** : Number of live births relative to number of women in county (b) <br />\n",
    "\n",
    "(a): years 2010-2016 <br />\n",
    "(b): 2013 Census Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "The website hosting the data is located at https://data.world/nrippner/ols-regression-challenge. These data were aggregated from a number of sources including the American Community Survey (https://www.census.gov), https://www.clinicaltrials.gov, and https://www.cancer.gov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets Start with importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model, metrics\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, normalize, StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import pylab as pl\n",
    "\n",
    "# Importing H2O\n",
    "import time, warnings, h2o, logging, os, sys, psutil, random\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "# from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Data\n",
    "df_cancer_data=pd.read_csv(r'cancer_reg.csv', encoding='latin-1')\n",
    "# df=pd.read_csv(r'C://Users//kaila//OneDrive//Desktop//DSMT//Assignment_2_Linear Models//cancer_reg.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cancer_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns PctSomeCol18_24, PctEmployed16_Over and PctPrivateCoverageAlone have some null value.<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer_data.loc[(df_cancer_data['MedianAge'] > 0) & (df_cancer_data['MedianAge'] <= 40), 'MedianAge'] = int(1)\n",
    "df_cancer_data.loc[(df_cancer_data['MedianAge'] > 40) & (df_cancer_data['MedianAge'] <= 50), 'MedianAge'] = int(2)\n",
    "df_cancer_data.loc[(df_cancer_data['MedianAge'] > 50), 'MedianAge'] = int(3)\n",
    "df_cancer_data['MedianAge']=df_cancer_data['MedianAge'].round(0).astype(int)\n",
    "\n",
    "df_cancer_data['MedianAge'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changed MedianAge column to categorical column.\n",
    "\n",
    "    | MedianAge | Categorical Value   | Occurence  |\n",
    "    |-----------|---------------------|------------|\n",
    "    | 0 to 40   | 1                   | 1270       |\n",
    "    | 40 to 50  | 2                   | 1621       |\n",
    "    | Above 50  | 3                   | 156        |\n",
    "\n",
    "Converted all values to integer type to make computation easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer_data['povertyPercent'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer_data['isPoor'] = np.where(df_cancer_data['povertyPercent'] <= 15.90, 0 ,1)\n",
    "df_cancer_data['isPoor'].value_counts()\n",
    "# remove column povertyPercent;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poverty percent is impotant factor when estimating death rate in cancer patients. <br />\n",
    "Creating binary variable that can be used in linear regression is valuable.<br /> \n",
    "- Created new binary column isPoor based on povertyPercent. \n",
    "- If povertyPercent below mean then value of isPoor is 0 else 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer_data[['PctEmployed16_Over','PctPrivateCoverageAlone','PctSomeCol18_24']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer_data['PctEmployed16_Over'] = pd.to_numeric(df_cancer_data['PctEmployed16_Over'], errors='coerce').fillna(54.50)\n",
    "df_cancer_data['PctPrivateCoverageAlone'] = pd.to_numeric(df_cancer_data['PctPrivateCoverageAlone'], errors='coerce').fillna(48.70)\n",
    "df_cancer_data['PctSomeCol18_24'] = pd.to_numeric(df_cancer_data['PctSomeCol18_24'], errors='coerce').fillna(40.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cancer_data[['PctEmployed16_Over','PctPrivateCoverageAlone','PctSomeCol18_24']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to fill null value with either mean or median to avoid skewness <br />\n",
    "We replace the null value column with median values(50%) <br />\n",
    "After Replacing values there is very little changes in overall description and thats good sign that our dataset is still close to the original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dummy columns for MedianAge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create dummy columns\n",
    "dummies = pd.get_dummies(df_cancer_data.MedianAge, prefix='MedianAge').iloc[:, 0:]\n",
    "# concate dummy columns with main dataframe df\n",
    "df_cancer_data = pd.concat([df_cancer_data, dummies], axis=1)\n",
    "# df=df.drop('MedianAge', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_val = df_cancer_data[['TARGET_deathRate','incidenceRate','medIncome','PctHS25_Over','PctEmployed16_Over','povertyPercent','PctUnemployed16_Over','PctPrivateCoverage','PctPrivateCoverageAlone','PctPublicCoverage','PctPublicCoverageAlone','MedianAge_1','MedianAge_2','MedianAge_3','isPoor']]\n",
    "\n",
    "std_scale = StandardScaler().fit(std_val)\n",
    "df_std = std_scale.transform(std_val)\n",
    "print(std_scale)\n",
    "print(df_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax_val = df_cancer_data[['TARGET_deathRate','incidenceRate','medIncome','PctHS25_Over','PctEmployed16_Over','povertyPercent','PctUnemployed16_Over','PctPrivateCoverage','PctPrivateCoverageAlone','PctPublicCoverage','PctPublicCoverageAlone','MedianAge_1','MedianAge_2','MedianAge_3','isPoor']]\n",
    "minmax_scale = MinMaxScaler().fit(minmax_val)\n",
    "print(minmax_scale)\n",
    "df_minmax = minmax_scale.transform(minmax_val)\n",
    "print(df_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "for f in df_cancer_data.columns:\n",
    "    if df_cancer_data[f].dtype=='object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(np.unique(list(df_cancer_data[f].values) ))\n",
    "        df_cancer_data[f] = lbl.transform(list(df_cancer_data[f].values))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Z-Score \n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "z = np.abs(stats.zscore(df_cancer_data[['TARGET_deathRate','incidenceRate','medIncome','PctHS25_Over','PctEmployed16_Over','povertyPercent','PctBachDeg25_Over','PctUnemployed16_Over','PctPrivateCoverage','PctPrivateCoverageAlone','PctPublicCoverage','PctPublicCoverageAlone','MedianAge_1','MedianAge_2','MedianAge_3']]))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(df_cancer_data, col_name):\n",
    "    if ((col_name!='binnedInc')&(col_name!='Geography')&(col_name!='PctSomeCol18_24')&(col_name!='MedianAge_1')&(col_name!='MedianAge_2')&(col_name!='MedianAge_3')):\n",
    "        q1 = df_cancer_data[col_name].quantile(0.10)\n",
    "        q3 = df_cancer_data[col_name].quantile(0.90)\n",
    "\n",
    "#         print (q1,q3)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound  = q1 - (1.5  * iqr)\n",
    "        upper_bound = q3 + (1.5 * iqr)\n",
    "\n",
    "        out_df=df_cancer_data.loc[(df_cancer_data[col_name] > lower_bound) & (df_cancer_data[col_name] < upper_bound)]\n",
    "        df_cancer_data[col_name] = out_df[col_name]\n",
    "        df_cancer_data[col_name] = pd.to_numeric(df_cancer_data[col_name], errors='coerce').fillna(df_cancer_data[col_name].mean())\n",
    "        return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_cancer_data:\n",
    "     remove_outlier(df_cancer_data,df_cancer_data[column].name)\n",
    "#     print(df[column].name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the relationship significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_cancer_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(data=df_cancer_data.iloc[:,2:].corr(),annot=True,fmt='.2f',cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = df_cancer_data[['TARGET_deathRate','incidenceRate','medIncome','povertyPercent','PctHS25_Over','PctEmployed16_Over','PctUnemployed16_Over','PctPrivateCoverage','PctPrivateCoverageAlone','PctPublicCoverage','PctPublicCoverageAlone']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,20))\n",
    "sns.heatmap(df_cancer_data.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_val = df_cancer_data[['TARGET_deathRate','incidenceRate','medIncome','PctHS25_Over','PctEmployed16_Over','povertyPercent','PctBachDeg25_Over']]\n",
    "x2_val = df_cancer_data[['TARGET_deathRate','PctUnemployed16_Over','PctPrivateCoverage','PctPrivateCoverageAlone','PctPublicCoverage','PctPublicCoverageAlone']]\n",
    "sns.set(style=\"ticks\")\n",
    "sns.pairplot(x1_val,palette=\"husl\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "sns.pairplot(x2_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependant Variable: Target_deathRate <br />\n",
    "\n",
    "In our dataset there are 35 original charecteristic out which 11 charecteristics have significant relationship to ur dependant variable. We will consider them as our predictors for our analysis<br />\n",
    "\n",
    "Independant Variables: ['TARGET_deathRate','incidenceRate','medIncome','povertyPercent','PctHS25_Over',\n",
    "'PctEmployed16_Over','PctUnemployed16_Over','PctPrivateCoverage','PctPrivateCoverageAlone',\n",
    "'PctPublicCoverage','PctPublicCoverageAlone']\n",
    "\n",
    "| Predictor Name                | Correlation         | Nature of relation       |\n",
    "|-------------------------------|---------------------|--------------------------|\n",
    "| incidenceRate                 |  0.45               | Positively Correlated    |\n",
    "| medIncome                     | -0.43               | Negatively Correlated    |\n",
    "| povertyPercent                |  0.43               | Positively Correlated    |\n",
    "| PctHS25_Over                  |  0.4                | Positively Correlated    |\n",
    "| PctEmployed16_Over            | -0.4                | Negatively Correlated    |\n",
    "| PctUnemployed16_Over          |  0.38               | Positively Correlated    |\n",
    "| PctPrivateCoverage            | -0.39               | Negatively Correlated    |\n",
    "| PctPrivateCoverageAlone       | -0.33               | Negatively Correlated    |\n",
    "| PctPublicCoverage             |  0.4                | Positively Correlated    |\n",
    "| PctPublicCoverageAlone        |  0.45               | Positively Correlated    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df_cancer_data['TARGET_deathRate']\n",
    "x1 = df_cancer_data[['incidenceRate','PctHS25_Over','PctUnemployed16_Over','PctPrivateCoverage','MedianAge_3','isPoor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add constant in metric form \n",
    "x=sm.add_constant(x1,prepend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = sm.OLS(y_train.apply(pd.to_numeric),X_train.apply(pd.to_numeric)).fit()\n",
    "results = sm.OLS(y_train,X_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=results.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Y-Test vs Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.scatter(y_test, predictions)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the lower values on the X-axis and  higher values on the X-axis the points are not near the regression line.\n",
    "- Plots shows there is varience in between y_test and Predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Evaluation Matric -RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower the RSME better the model\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error\n",
    "crossVal_Model1=np.sqrt(mean_squared_error(y_test,predictions))\n",
    "crossVal_Model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the model good enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "colors = np.array('b g r c m y'.split()) #Different colors for plotting\n",
    "\n",
    "fig,axes = plt.subplots(nrows =2,ncols=2, sharey=True,figsize = (15,10))\n",
    "plt.tight_layout()\n",
    "row = 0\n",
    "iteration = 0\n",
    "for j in range(0,len(x1.columns[:-3])):\n",
    "    iteration+=1\n",
    "    if(j%2==0):\n",
    "        k = 0\n",
    "    else:\n",
    "        k = 1\n",
    "    sns.distplot(x1[x1.columns[j]],kde=False,hist_kws=dict(edgecolor=\"w\", linewidth=2),\n",
    "                 color = np.random.choice(colors) ,ax=axes[row][k])\n",
    "    if(iteration%2==0):\n",
    "        row+=1\n",
    "        plt.ylim(0,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All predictors are normally distributed, incidenceRate and PctUnemployed16_Over are skewed to the left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are residuals normally distributed?\n",
    "#### In regression analysis, the difference between the observed value of the dependent variable (i.e TARGET_deathRate) and the predicted value (predictions) is called the residual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram superimposed by normal curve\n",
    "plt.figure(figsize=(10,6))\n",
    "import scipy.stats as stats\n",
    "mu = np.mean(results.resid)\n",
    "sigma = np.std(results.resid)\n",
    "pdf = stats.norm.pdf(sorted(results.resid), mu, sigma)\n",
    "plt.hist(results.resid, bins=100, normed=True)\n",
    "plt.plot(sorted(results.resid), pdf, color='r', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure above is histogram superimposed by normal curve.\n",
    "- The distribution of the residuals does not adhere perfectly to a normal distribution (skew=0, excess kurtosis=0).\n",
    "- There is a small number of outliers to the left, the tails appear slightly fatter than, and the distribution has moderate kurtosis (i.e 5.81)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQplot\n",
    "fig, [ax1, ax2] = plt.subplots(1,2, figsize=(15,5))\n",
    "sm.qqplot(results.resid, stats.t, fit=True, line='45', ax = ax1)\n",
    "ax1.set_title(\"t distribution\")\n",
    "sm.qqplot(results.resid, stats.norm, fit=True, line='45', ax=ax2)\n",
    "ax2.set_title(\"normal distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The qqplots confirm that the residuals adhere more closely to the t- than normal distribution (fatter tails). <br />\n",
    "- A few prominent outliers are visible at the lower and upper extreme. <br />\n",
    "- All-in-all, despite these imperfections, I consider the distribution of residuals to be adequate. <br />\n",
    "- However, we should investigate the nature of the more extreme outliers. <br />\n",
    "- We also may want to try to add additional information or to change the predictors (We will be doing it in Model 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are any model assumptions violated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homoscedasticity & Heteroscedasticity\n",
    "Homoscedasticity means that the variance around the regression line is the same for all values of the predictor variable (i.e TARGET_deathRate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predicted vs actual\n",
    "plt.figure(figsize=(14,7))\n",
    "sns.regplot(y_train, results.fittedvalues, line_kws={'color':'r', 'alpha':0.3, \n",
    "                                              'linestyle':'--', 'linewidth':2}, \n",
    "            scatter_kws={'alpha':0.5})\n",
    "plt.ylim(0,300)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Fitted Values')\n",
    "plt.show()\n",
    "print(\"Pearson R: \", stats.pearsonr(results.fittedvalues, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the plot we can infer that fitted values and actual values are collinear.\n",
    "- The fiitet values sticks to the reggression line so there is no assumption violated.\n",
    "- For the lower values on the X-axis and  higher values on the X-axis the points are all very near the regression line.\n",
    "- Consistent with our reported R^2 value, we now visualize the strong correlation between actual and predicted values.\n",
    "- no assumption are violated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting actual values versus residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "ys = lowess(results.resid.values, y_train, frac=0.2)\n",
    "ys = pd.DataFrame(ys, index=range(len(ys)), columns=['a', 'b'])\n",
    "ys = ys.sort_values(by='a')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,9))\n",
    "plt.scatter(y_train, results.resid, alpha=0.5, s=25)\n",
    "plt.axhline(y=0, color='r', linestyle=\"--\", alpha=0.5)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "\n",
    "plt.plot(ys.a, ys.b, c='green', linewidth=2, label=\"Lowess\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Pearson R:\", stats.pearsonr(y_train, results.resid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A residual plot is a graph that shows the residuals on the vertical axis and the independent variable on the horizontal axis.\n",
    "- This chart suggests values are plottet randomly and linear Model is appropriate for data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelL1 = LinearRegression()\n",
    "model = modelL1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_linear=model.predict(X_test)\n",
    "predictions_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Both the output for first 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('Actual Predictions :' )\n",
    "print(predictions[0:5])\n",
    "print ('Cross-Validation Predictions :')\n",
    "print(predictions_linear[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- from both the results we can infer that the our predictions are currect for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# R-Square value calculted 5 times\n",
    "scores_train = cross_val_score(model, X_train,y_train, cv=5)\n",
    "print(scores_train)\n",
    "print(\"Accuracy:  %0.2f (+/- %0.2f): \" % (scores_train.mean(),scores_train.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test = cross_val_score(model, X_test,y_test, cv=5)\n",
    "print(scores_train )\n",
    "print(\"Accuracy:  %0.2f (+/- %0.2f): \" % (scores_train.mean(),scores_train.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "print(sns.heatmap(x1.corr(), annot=True,cmap='coolwarm'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only PctPrivateCoverage has high correlation with PctUnemployed16_over and isPoor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply variance inflation factors to assess for multicollinearity. VIFs, by performing an independent variable on the design matrix comprising all the other independent variables, allows us to assess the degree to which that independent variable is orthogonal the others. \n",
    "Larger VIFs indicate multicollinearity. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([[var, variance_inflation_factor(x.values, x.columns.get_loc(var))] for var in x.columns],\n",
    "                   index=range(x.shape[1]), columns=['Variable', 'VIF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance Inflation Factor (VIF) â€“ the variance inflation factor of the linear regression is defined as VIF = 1/T. With VIF > 10 there is an indication that multicollinearity may be present; with VIF > 100 there is certainly multicollinearity among the variables. \n",
    "In the above model, Multicollinearity is present.\n",
    "\n",
    "All the predictors have acceptable VIF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In Backword Selection method; we are going to check which predictors performs well and we will be removing predictots which have high P-stats and comparing the output. \n",
    "- Here our Traget variable is 'isPoor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regularization is a method for \"constraining\" or \"regularizing\" the size of the coefficients, thus \"shrinking\" them towards zero.\n",
    "- It reduces model variance which minimizes overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a regularized linear regression model, we minimize the sum of RSS and a \"penalty term\" that penalizes coefficient size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm=df_cancer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm=df_norm.drop('binnedInc', axis=1)\n",
    "df_norm=df_norm.drop('Geography', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression with an alpha of 0.5\n",
    "y_norm=df_norm['TARGET_deathRate']\n",
    "# x_norm = df_norm[['TARGET_deathRate','incidenceRate','medIncome','povertyPercent','PctHS25_Over','PctEmployed16_Over','PctUnemployed16_Over','PctPrivateCoverage','PctPrivateCoverageAlone','PctPublicCoverage','PctPublicCoverageAlone']]\n",
    "x_norm = df_norm[['incidenceRate','PctHS25_Over','PctUnemployed16_Over','PctPrivateCoverage','MedianAge_3','isPoor']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_norm,y_norm,test_size=0.2)\n",
    "ridge = Ridge(fit_intercept=True, alpha=0.5)\n",
    "ridge.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge.predict(X_test)\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"TARGET_deathRate: $Y_i$\")\n",
    "plt.ylabel(\"Predicted TARGET_deathRate: $\\hat{y}_i$\")\n",
    "plt.title(\"Ridge Regression - TARGET_deathRate vs Predicted TARGET_deathRate: $Y_i$ vs $\\hat{y}_i$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Evaluation Matrics -RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_norm = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "rmse_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "# Train the model using the training sets\n",
    "linreg.fit(x_norm,y_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kf=np.array(x_norm)\n",
    "y_kf=np.array(y_norm)\n",
    "# Define the split - into 2 folds \n",
    "kf=KFold(n_splits=5,shuffle=False, random_state=None) \n",
    "#Returns the number of splitting iterations in the cross-validator\n",
    "kf.get_n_splits(X_kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X_kf):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_kf[train_index], X_kf[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for train, test in kf.split(X_kf):\n",
    "    linreg.fit(X_kf[train],y_kf[train])\n",
    "    scores.append(np.sqrt(metrics.mean_squared_error(y_kf[test], linreg.predict(X_kf[test]))))\n",
    "# scores\n",
    "np.around(scores, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean           : ',round(np.mean(scores),2))\n",
    "print('Median         : ',round(np.median(scores),2))\n",
    "print('Std. Deviation : ',round(np.std(scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stats(m, ncv, cv):\n",
    "    print('Method: %s' %m)\n",
    "    print('RMSE on no CV training: %.3f' %ncv)\n",
    "    print('RMSE on 5-fold CV: %.3f' %cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_stats('Simple Linear Regression',rmse_norm ,np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ridge Regression')\n",
    "print('alpha\\t RMSE_train\\t RMSE_cv\\n')\n",
    "alpha = np.linspace(.01,20,50)\n",
    "t_rmse = np.array([])\n",
    "cv_rmse = np.array([])\n",
    "\n",
    "for a in alpha:\n",
    "    ridge = Ridge(fit_intercept=True, alpha=a)  \n",
    "    # computing the RMSE on training data\n",
    "    ridge.fit(X_kf,y_kf)\n",
    "    y_pred = ridge.predict(X_kf)\n",
    "    err = y_pred-y_kf    \n",
    "    # Dot product of error vector with itself gives us the sum of squared errors\n",
    "    total_error = np.dot(err,err)\n",
    "    rmse_train = np.sqrt(total_error/len(y_pred))\n",
    "\n",
    "    # computing RMSE using 5-fold cross validation\n",
    "    kf = KFold(len(X_kf))\n",
    "    xval_err = 0\n",
    "    for train, test in kf.split(X_kf):\n",
    "        ridge.fit(X_kf[train], y_kf[train])\n",
    "        y_pred = ridge.predict(X_kf[test])\n",
    "        err = y_pred - y_kf[test]\n",
    "        xval_err += np.dot(err,err)\n",
    "    rmse_cv = np.sqrt(xval_err/len(X_kf))\n",
    "    \n",
    "    t_rmse = np.append(t_rmse, [rmse_train])\n",
    "    cv_rmse = np.append(cv_rmse, [rmse_cv])\n",
    "    print('{:.3f}\\t {:.4f}\\t\\t {:.4f}'.format(a,rmse_train,rmse_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "pl.plot(alpha, t_rmse, label='RMSE-Train')\n",
    "pl.plot(alpha, cv_rmse, label='RMSE_Cross_Val')\n",
    "pl.legend( ('Ridge RMSE-Train', 'Ridge RMSE_Cross_Val') )\n",
    "pl.ylabel('RMSE')\n",
    "pl.xlabel('Alpha')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Ridge Regression:\n",
    "The cross validation between RMSE_train and RMSE_cv shows the root mean square error for train and cross validation values  very close "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing H2O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialising the H20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_memory=0.95\n",
    "virtual_memory=psutil.virtual_memory()\n",
    "print(\"Virtual Memory Size: \",virtual_memory)\n",
    "min_mem_size=int(round(int(pct_memory*virtual_memory.available)/1073741824,0))\n",
    "print(\"Minimum Memory Size: \",min_mem_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Dataset into H2O frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=None\n",
    "all_variables=None\n",
    "test_path=None\n",
    "# target='search_term'\n",
    "target=None\n",
    "nthreads=1 \n",
    "min_mem_size= min_mem_size \n",
    "# run_time=4000\n",
    "classification=False\n",
    "scale=False\n",
    "max_models=None    \n",
    "model_path=None\n",
    "balance_y=False \n",
    "balance_threshold=0.2\n",
    "name=None \n",
    "server_path=None  \n",
    "analysis=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def alphabet(n):\n",
    "  alpha='0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'    \n",
    "  str=''\n",
    "  r=len(alpha)-1   \n",
    "  while len(str)<n:\n",
    "    i=random.randint(0,r)\n",
    "    str+=alpha[i]   \n",
    "  return str\n",
    "  \n",
    "  \n",
    "def set_meta_data(analysis,run_id,server,data,test,model_path,target,run_time,classification,scale,model,balance,balance_threshold,name,path,nthreads,min_mem_size):\n",
    "  m_data={}\n",
    "  m_data['start_time'] = time.time()\n",
    "  m_data['target']=target\n",
    "#   m_data['predictors']=predictors\n",
    "  m_data['server_path']=server\n",
    "  m_data['data_path']=data \n",
    "  m_data['test_path']=test\n",
    "  m_data['max_models']=model\n",
    "  m_data['run_time']=run_time\n",
    "  m_data['run_id'] =run_id\n",
    "  m_data['scale']=scale\n",
    "  m_data['classification']=classification\n",
    "  m_data['scale']=False\n",
    "  m_data['model_path']=model_path\n",
    "  m_data['balance']=balance\n",
    "  m_data['balance_threshold']=balance_threshold\n",
    "  m_data['project'] =name\n",
    "  m_data['end_time'] = time.time()\n",
    "  m_data['execution_time'] = 0.0\n",
    "  m_data['run_path'] =path\n",
    "  m_data['nthreads'] = nthreads\n",
    "  m_data['min_mem_size'] = min_mem_size\n",
    "  m_data['analysis'] = analysis\n",
    "  m_data['Main_Eval_metrix'] = \"RMSE\"\n",
    "  return m_data\n",
    "\n",
    "\n",
    "def dict_to_json(dct,n):\n",
    "  j = json.dumps(dct, indent=4)\n",
    "  f = open(n, 'w')\n",
    "  print(j, file=f)\n",
    "  f.close()\n",
    "  \n",
    "  \n",
    "def stackedensemble(mod):\n",
    "    coef_norm=None\n",
    "    try:\n",
    "      metalearner = h2o.get_model(mod.metalearner()['name'])\n",
    "      coef_norm=metalearner.coef_norm()\n",
    "    except:\n",
    "      pass        \n",
    "    return coef_norm\n",
    "\n",
    "def stackedensemble_df(df):\n",
    "    bm_algo={ 'GBM': None,'GLM': None,'DRF': None,'XRT': None,'Dee': None}\n",
    "    for index, row in df.iterrows():\n",
    "      if len(row['model_id'])>3:\n",
    "        key=row['model_id'][0:3]\n",
    "        if key in bm_algo:\n",
    "          if bm_algo[key] is None:\n",
    "                bm_algo[key]=row['model_id']\n",
    "    bm=list(bm_algo.values()) \n",
    "    bm=list(filter(None.__ne__, bm))             \n",
    "    return bm\n",
    "\n",
    "def se_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['auc']=modl.auc()   \n",
    "    d['roc']=modl.roc()\n",
    "    d['mse']=modl.mse()   \n",
    "    d['null_degrees_of_freedom']=modl.null_degrees_of_freedom()\n",
    "    d['null_deviance']=modl.null_deviance()\n",
    "    d['residual_degrees_of_freedom']=modl.residual_degrees_of_freedom()   \n",
    "    d['residual_deviance']=modl.residual_deviance()\n",
    "    d['rmse']=modl.rmse()\n",
    "    return d\n",
    "\n",
    "def get_model_by_algo(algo,models_dict):\n",
    "    mod=None\n",
    "    mod_id=None    \n",
    "    for m in list(models_dict.keys()):\n",
    "        if m[0:3]==algo:\n",
    "            mod_id=m\n",
    "            mod=h2o.get_model(m)      \n",
    "    return mod,mod_id     \n",
    "    \n",
    "    \n",
    "def gbm_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['varimp']=modl.varimp()  \n",
    "    return d\n",
    "    \n",
    "    \n",
    "def dl_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['varimp']=modl.varimp()  \n",
    "    return d\n",
    "    \n",
    "    \n",
    "def drf_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['varimp']=modl.varimp()  \n",
    "    d['roc']=modl.roc()      \n",
    "    return d\n",
    "    \n",
    "def xrt_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['varimp']=modl.varimp()  \n",
    "    d['roc']=modl.roc()      \n",
    "    return d\n",
    "    \n",
    "    \n",
    "def glm_stats(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['coef']=modl.coef()  \n",
    "    d['coef_norm']=modl.coef_norm()      \n",
    "    return d\n",
    "    \n",
    "def model_performance_stats(perf):\n",
    "    d={}\n",
    "    try:    \n",
    "      d['mse']=perf.mse()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['rmse']=perf.rmse() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['null_degrees_of_freedom']=perf.null_degrees_of_freedom()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['residual_degrees_of_freedom']=perf.residual_degrees_of_freedom()\n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['residual_deviance']=perf.residual_deviance() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['null_deviance']=perf.null_deviance() \n",
    "    except:\n",
    "      pass      \n",
    "    try:    \n",
    "      d['aic']=perf.aic() \n",
    "    except:\n",
    "      pass      \n",
    "    try:\n",
    "      d['logloss']=perf.logloss() \n",
    "    except:\n",
    "      pass    \n",
    "    try:\n",
    "      d['auc']=perf.auc()\n",
    "    except:\n",
    "      pass  \n",
    "    try:\n",
    "      d['gini']=perf.gini()\n",
    "    except:\n",
    "      pass    \n",
    "    return d\n",
    "    \n",
    "def impute_missing_values(df, x, scal=False):\n",
    "    # determine column types\n",
    "    ints, reals, enums = [], [], []\n",
    "    for key, val in df.types.items():\n",
    "        if key in x:\n",
    "            if val == 'enum':\n",
    "                enums.append(key)\n",
    "            elif val == 'int':\n",
    "                ints.append(key)            \n",
    "            else: \n",
    "                reals.append(key)    \n",
    "    _ = df[reals].impute(method='mean')\n",
    "    _ = df[ints].impute(method='median')\n",
    "    if scal:\n",
    "        df[reals] = df[reals].scale()\n",
    "        df[ints] = df[ints].scale()    \n",
    "    return\n",
    "\n",
    "\n",
    "def get_independent_variables(df, targ):\n",
    "    C = [name for name in df.columns if name != targ]\n",
    "    # determine column types\n",
    "    ints, reals, enums = [], [], []\n",
    "    for key, val in df.types.items():\n",
    "        if key in C:\n",
    "            if val == 'enum':\n",
    "                enums.append(key)\n",
    "            elif val == 'int':\n",
    "                ints.append(key)            \n",
    "            else: \n",
    "                reals.append(key)    \n",
    "    x=ints+enums+reals\n",
    "    return x\n",
    "    \n",
    "def get_all_variables_csv(i):\n",
    "    ivd={}\n",
    "    try:\n",
    "      iv = pd.read_csv(i,header=None)\n",
    "    except:\n",
    "      sys.exit(1)    \n",
    "    col=iv.values.tolist()[0]\n",
    "    dt=iv.values.tolist()[1]\n",
    "    i=0\n",
    "    for c in col:\n",
    "      ivd[c.strip()]=dt[i].strip()\n",
    "      i+=1        \n",
    "    return ivd\n",
    "    \n",
    "    \n",
    "\n",
    "def check_all_variables(df,dct,y=None):     \n",
    "    targ=list(dct.keys())     \n",
    "    for key, val in df.types.items():\n",
    "        if key in targ:\n",
    "          if dct[key] not in ['real','int','enum']:                      \n",
    "            targ.remove(key)  \n",
    "    for key, val in df.types.items():\n",
    "        if key in targ:            \n",
    "          if dct[key] != val:\n",
    "            print('convert ',key,' ',dct[key],' ',val)\n",
    "            if dct[key]=='enum':\n",
    "                try:\n",
    "                  df[key] = df[key].asfactor() \n",
    "                except:\n",
    "                  targ.remove(key)                 \n",
    "            if dct[key]=='int': \n",
    "                try:                \n",
    "                  df[key] = df[key].asnumeric() \n",
    "                except:\n",
    "                  targ.remove(key)                  \n",
    "            if dct[key]=='real':\n",
    "                try:                \n",
    "                  df[key] = df[key].asnumeric()  \n",
    "                except:\n",
    "                  targ.remove(key)                  \n",
    "    if y is None:\n",
    "      y=df.columns[-1] \n",
    "    if y in targ:\n",
    "      targ.remove(y)\n",
    "    else:\n",
    "      y=targ.pop()            \n",
    "    return targ    \n",
    "    \n",
    "def predictions(mod,data,run_id):\n",
    "    test = h2o.import_file(data)\n",
    "    mod_perf=mod_best.model_performance(test)\n",
    "              \n",
    "    stats_test={}\n",
    "    stats_test=model_performance_stats(mod_perf)\n",
    "\n",
    "    n=run_id+'_test_stats.json'\n",
    "    dict_to_json(stats_test,n) \n",
    "\n",
    "    try:    \n",
    "      cf=mod_perf.confusion_matrix(metrics=[\"f1\",\"f2\",\"f0point5\",\"accuracy\",\"precision\",\"recall\",\"specificity\",\"absolute_mcc\",\"min_per_class_accuracy\",\"mean_per_class_accuracy\"])\n",
    "      cf_df=cf[0].table.as_data_frame()\n",
    "      cf_df.to_csv(run_id+'_test_confusion_matrix.csv')\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    predictions = mod_best.predict(test)\n",
    "    predictions_df=test.cbind(predictions).as_data_frame() \n",
    "    predictions_df.to_csv(run_id+'_predictions.csv')\n",
    "    return\n",
    "\n",
    "def predictions_test(mod,test,run_id):\n",
    "    mod_perf=mod_best.model_performance(test)          \n",
    "    stats_test={}\n",
    "    stats_test=model_performance_stats(mod_perf)\n",
    "    n=run_id+'_test_stats.json'\n",
    "    dict_to_json(stats_test,n) \n",
    "    try:\n",
    "      cf=mod_perf.confusion_matrix()\n",
    "#      cf=mod_perf.confusion_matrix(metrics=[\"f1\",\"f2\",\"f0point5\",\"accuracy\",\"precision\",\"recall\",\"specificity\",\"absolute_mcc\",\"min_per_class_accuracy\",\"mean_per_class_accuracy\"])\n",
    "      cf_df=cf.table.as_data_frame()\n",
    "      cf_df.to_csv(run_id+'_test_confusion_matrix.csv')\n",
    "    except:\n",
    "      pass\n",
    "    predictions = mod_best.predict(test)    \n",
    "    predictions_df=test.cbind(predictions).as_data_frame() \n",
    "    predictions_df.to_csv(run_id+'_predictions.csv')\n",
    "    return predictions\n",
    "\n",
    "def check_X(x,df):\n",
    "    for name in x:\n",
    "        if name not in df.columns:\n",
    "          x.remove(name)  \n",
    "    return x    \n",
    "    \n",
    "    \n",
    "def get_stacked_ensemble(lst):\n",
    "    se=None\n",
    "    for model in model_set:\n",
    "      if 'BestOfFamily' in model:\n",
    "        se=model\n",
    "    if se is None:     \n",
    "      for model in model_set:\n",
    "        if 'AllModels'in model:\n",
    "          se=model           \n",
    "    return se       \n",
    "    \n",
    "def get_variables_types(df):\n",
    "    d={}\n",
    "    for key, val in df.types.items():\n",
    "        d[key]=val           \n",
    "    return d    \n",
    "\n",
    "def Variable_imp_list(modl):\n",
    "    d={}\n",
    "    d['algo']=modl.algo\n",
    "    d['model_id']=modl.model_id   \n",
    "    d['varimp']=modl.varimp()  \n",
    "    return d\n",
    "\n",
    "#  End Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_id=\"Runtime_1_333_Hyperparameter\"\n",
    "run_id=alphabet(9)\n",
    "if server_path==None:\n",
    "  server_path=os.path.abspath(os.curdir)\n",
    "os.chdir(server_path) \n",
    "run_dir = os.path.join(server_path,run_id)\n",
    "os.mkdir(run_id)\n",
    "os.chdir(run_id)\n",
    "\n",
    "# run_id to std_opt\n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile=run_id+'_autoh2o_log.zip'\n",
    "logs_path=os.path.join(run_dir,'logs')\n",
    "print(logs_path,logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a cluster\n",
    "port_no=random.randint(5555,55555)\n",
    "\n",
    "#  h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no) # start h2o\n",
    "try:\n",
    "  h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no) # start h2o\n",
    "except:\n",
    "  logging.critical('h2o.init')\n",
    "  h2o.download_all_logs(dirname=logs_path, filename=logfile)      \n",
    "  h2o.cluster().shutdown()\n",
    "  sys.exit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H2O_df = h2o.import_file(\"cancer_reg.csv\")\n",
    "H2O_df=h2o.H2OFrame(df_cancer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors=[x for x in H2O_df.columns if x not in ['TARGET_deathRate']]\n",
    "Target='TARGET_deathRate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time=333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = set_meta_data(analysis, run_id,server_path,data_path,test_path,model_path,target,run_time,classification,scale,max_models,balance_y,balance_threshold,name,run_dir,nthreads,min_mem_size)\n",
    "print(meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependent variable\n",
    "# assign target and inputs for classification or regression\n",
    "if target==None:\n",
    " target=H2O_df.columns[2]   #df['target_class']\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_variables is not None:\n",
    " ivd=get_all_variables_csv(all_variables)\n",
    " print(ivd)\n",
    " X=check_all_variables(H2O_df,ivd,y)\n",
    " print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent variables\n",
    "\n",
    "X = []\n",
    "if all_variables is None:\n",
    " X=get_independent_variables(H2O_df, y)\n",
    " print(X)\n",
    "else:\n",
    " ivd=get_all_variables_csv(all_variables)\n",
    " X=check_all_variables(H2O_df, ivd)\n",
    "\n",
    "\n",
    "X=check_X(X,H2O_df)\n",
    "\n",
    "# Add independent variables\n",
    "meta_data['X']=X\n",
    "\n",
    "\n",
    "# impute missing values\n",
    "_=impute_missing_values(H2O_df,X, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analysis == 2:\n",
    " classification=False\n",
    "elif analysis == 1:\n",
    " classification=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force target to be factors\n",
    "# Only 'int' or 'string' are allowed for asfactor(), got Target (Total orders):real\n",
    "\n",
    "if classification:\n",
    "   H2O_df[y] = H2O_df[y].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_y(y,df):\n",
    " ok=False\n",
    " C = [name for name in df.columns if name == y]\n",
    " for key, val in df.types.items():\n",
    "   if key in C:\n",
    "     if val in ['real','int','enum']:\n",
    "       ok=True\n",
    " return ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok=check_y(y,H2O_df)\n",
    "if not ok:\n",
    "   print(ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification=True\n",
    "if classification:\n",
    "   print(H2O_df[y].levels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allV=get_variables_types(H2O_df)\n",
    "# allV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data['variables']=allV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = H2OAutoML(max_runtime_secs = run_time, seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_start_time = time.time()\n",
    "aml.train(x=predictors, y=Target, training_frame=H2O_df)\n",
    "model_end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data['model_execution_time'] = time.time() - model_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comma saperated predictors can put in metadata file\n",
    "predictors_list=' ,'.join(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allV=get_variables_types(H2O_df)\n",
    "meta_data['variables']=allV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets print the Leaderboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_leaderboard_df=aml.leaderboard.as_data_frame()\n",
    "model_set=aml_leaderboard_df['model_id']\n",
    "mod_best=h2o.get_model(model_set[0])\n",
    "meta_data['mod_best']= h2o.get_model(model_set[0])._id \n",
    "meta_data['mod_best_algo']=h2o.get_model(model_set[0]).algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data['mod_best_algo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandaFrame = lb.as_data_frame()\n",
    "leaderboard_stats=run_id+'_leaderboard.json'\n",
    "df_pandaFrame.to_json(leaderboard_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "\n",
    "for rows in df_pandaFrame.iterrows():\n",
    "    \n",
    "    mod_best1=h2o.get_model(model_set[count])\n",
    "    count=count+1\n",
    "    hy_parameter = mod_best1.params\n",
    "    n= run_id + \"_\"+mod_best1._id + '_hy_parameter.json' \n",
    "    dict_to_json(hy_parameter,n)\n",
    "#     hy_parameter.to_json(file_name)\n",
    "#     print(hy_parameter)\n",
    "#     output = pd.DataFrame()\n",
    "#     output = output.append(hy_parameter, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models={}\n",
    "best_models=stackedensemble(mod_best)\n",
    "bm=[]\n",
    "if best_models is not None: \n",
    "  if 'Intercept' in best_models.keys():\n",
    "    del best_models['Intercept']\n",
    "  bm=list(best_models.keys())\n",
    "else:\n",
    "  best_models={}\n",
    "  bm=stackedensemble_df(aml_leaderboard_df)   \n",
    "  for b in bm:   \n",
    "    best_models[b]=None\n",
    "\n",
    "if mod_best1.model_id not in bm:\n",
    "    bm.append(mod_best.model_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data['models']=bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GBM_list=['Model_name','Leaderboard_rank','learn_rate','learn_rate_annealing','max_abs_leafnode_pred','pred_noise_bandwidth','distribution','tweedie_power','quantile_alpha','huber_alpha','categorical_encoding','max_depth','sample_rate','col_sample_rate','ntrees','nfolds']\n",
    "df_gbm = pd.DataFrame(columns=GBM_list)\n",
    "\n",
    "\n",
    "GLM_list=['Model_name','Leaderboard_rank','nfolds','seed','tweedie_variance_power','tweedie_link_power','alpha','lambda','missing_values_handling','standardize']\n",
    "df_glm = pd.DataFrame(columns=GLM_list)\n",
    "\n",
    "# DRF and XRT are the same\n",
    "DRF_list=['Model_name','Leaderboard_rank','nfolds','seed','mtries','categorical_encoding']\n",
    "df_drf = pd.DataFrame(columns=DRF_list)\n",
    "\n",
    "Deeplearn_list=['Model_name','Leaderboard_rank','balance_classes','categorical_encoding','class_sampling_factors','distribution','huber_alpha','max_after_balance_size','max_runtime_secs','missing_values_handling','model_id','quantile_alpha','seed','standardize','stopping_metric','stopping_rounds','stopping_tolerance','tweedie_power']\n",
    "df_Deeplearn = pd.DataFrame(columns=Deeplearn_list)\n",
    "\n",
    "count=0\n",
    "cnt=0\n",
    "# aml_leaderboard_df=aml.leaderboard.as_data_frame()\n",
    "# model_set=aml_leaderboard_df['model_id']\n",
    "rows_list = []\n",
    "for rows in df_pandaFrame.iterrows():\n",
    "    \n",
    "    mod_best1=h2o.get_model(model_set[count])\n",
    "    count=count+1\n",
    "    hy_parameter = mod_best1.params\n",
    "    \n",
    "    if (mod_best1.algo == 'gbm' ):\n",
    "#         print(mod_best1.varimp())\n",
    "        df_gbm=df_gbm.append({'Model_name':mod_best1.model_id,\n",
    "                                'Leaderboard_rank':count,\n",
    "                                'RMSE_VAL':mod_best1.rmse(xval=True),\n",
    "                                'learn_rate':hy_parameter['learn_rate']['actual'],\n",
    "                                'max_depth':hy_parameter['max_depth']['actual'],\n",
    "                                'sample_rate': hy_parameter['sample_rate']['actual'],\n",
    "                                'col_sample_rate':hy_parameter['col_sample_rate']['actual'],\n",
    "                                'ntrees':hy_parameter['ntrees']['actual'],\n",
    "                                'nfolds':hy_parameter['nfolds']['actual'],\n",
    "                                'learn_rate_annealing':hy_parameter['learn_rate_annealing']['actual'],\n",
    "                                'max_abs_leafnode_pred':hy_parameter['max_abs_leafnode_pred']['actual'],\n",
    "                                'pred_noise_bandwidth':hy_parameter['pred_noise_bandwidth']['actual'],\n",
    "                                'distribution':hy_parameter['distribution']['actual'],\n",
    "                                'tweedie_power':hy_parameter['tweedie_power']['actual'],\n",
    "                                'quantile_alpha':hy_parameter['quantile_alpha']['actual'],\n",
    "                                'huber_alpha':hy_parameter['huber_alpha']['actual'],\n",
    "                                'categorical_encoding':hy_parameter['categorical_encoding']['actual']},\n",
    "                             ignore_index=True)\n",
    "     \n",
    "    elif (mod_best1.algo == 'glm'):\n",
    "        df_glm=df_glm.append({'Model_name':mod_best1.model_id,\n",
    "                                'Leaderboard_rank':count,\n",
    "                                'nfolds':hy_parameter['nfolds']['actual'],\n",
    "                                'seed':hy_parameter['seed']['actual'],\n",
    "                                'tweedie_variance_power':hy_parameter['tweedie_variance_power']['actual'],\n",
    "                                'tweedie_link_power':hy_parameter['tweedie_link_power']['actual'],\n",
    "                                'alpha':hy_parameter['alpha']['actual'],\n",
    "                                'lambda':hy_parameter['lambda']['actual'],\n",
    "                                'missing_values_handling':hy_parameter['missing_values_handling']['actual'],\n",
    "                                'standardize':hy_parameter['standardize']['actual']},\n",
    "                             ignore_index=True)\n",
    "    \n",
    "    elif (mod_best1.algo == 'drf'):\n",
    "        df_drf=df_drf.append({'Model_name':mod_best1.model_id,\n",
    "                                'Leaderboard_rank':count,\n",
    "                                'nfolds':hy_parameter['nfolds']['actual'],\n",
    "                                'seed':hy_parameter['seed']['actual'],\n",
    "                                'mtries':hy_parameter['mtries']['actual'],\n",
    "                                'categorical_encoding':hy_parameter['categorical_encoding']['actual']},\n",
    "                             ignore_index=True)\n",
    "        \n",
    "    elif (mod_best1.algo == 'deeplearning'):\n",
    "        df_Deeplearn=df_Deeplearn.append({'Model_name':mod_best1.model_id,\n",
    "                                'Leaderboard_rank':count,\n",
    "                                'balance_classes': hy_parameter['balance_classes']['actual'],\n",
    "                                'max_after_balance_size': hy_parameter['max_after_balance_size']['actual'],\n",
    "                                'class_sampling_factors':hy_parameter['class_sampling_factors']['actual'],\n",
    "                                'activation':hy_parameter['activation']['actual'],\n",
    "                                'hidden':hy_parameter['hidden']['actual'],\n",
    "                                'epochs':hy_parameter['epochs']['actual'],\n",
    "                                'train_samples_per_iteration':hy_parameter['train_samples_per_iteration']['actual'],\n",
    "                                'target_ratio_comm_to_comp':hy_parameter['target_ratio_comm_to_comp']['actual'],\n",
    "                                'seed':hy_parameter['seed']['actual'],\n",
    "                                'adaptive_rate':hy_parameter['adaptive_rate']['actual'],\n",
    "                                'rho':hy_parameter['rho']['actual'],\n",
    "                                'epsilon':hy_parameter['epsilon']['actual'],\n",
    "                                'rate':hy_parameter['rate']['actual'],\n",
    "                                'rate_annealing':hy_parameter['rate_annealing']['actual'],\n",
    "                                'rate_decay':hy_parameter['rate_decay']['actual'],\n",
    "                                'momentum_start':hy_parameter['momentum_start']['actual'],\n",
    "                                'momentum_ramp':hy_parameter['momentum_ramp']['actual'],\n",
    "                                'momentum_stable':hy_parameter['momentum_stable']['actual'],                                          \n",
    "                                'nesterov_accelerated_gradient':hy_parameter['nesterov_accelerated_gradient']['actual'],\n",
    "                                'input_dropout_ratio':hy_parameter['input_dropout_ratio']['actual'],\n",
    "                                'hidden_dropout_ratios':hy_parameter['hidden_dropout_ratios']['actual'],\n",
    "                                'l1':hy_parameter['l1']['actual'],\n",
    "                                'initial_weight_distribution':hy_parameter['initial_weight_distribution']['actual'],\n",
    "                                'initial_weight_scale':hy_parameter['initial_weight_scale']['actual'],                                          \n",
    "                                'l2':hy_parameter['l2']['actual'],\n",
    "                                'max_w2':hy_parameter['max_w2']['actual'],\n",
    "                                'loss':hy_parameter['loss']['actual'],\n",
    "                                'initial_weights':hy_parameter['initial_weights']['actual'],\n",
    "                                'initial_biases':hy_parameter['initial_biases']['actual'],\n",
    "                                'distribution':hy_parameter['distribution']['actual'],                                          \n",
    "                                'tweedie_power':hy_parameter['tweedie_power']['actual'],\n",
    "                                'quantile_alpha':hy_parameter['quantile_alpha']['actual'],\n",
    "                                'score_interval':hy_parameter['score_interval']['actual'],\n",
    "                                'score_training_samples':hy_parameter['score_training_samples']['actual'],\n",
    "                                'score_validation_samples':hy_parameter['score_validation_samples']['actual'],\n",
    "                                'score_duty_cycle':hy_parameter['score_duty_cycle']['actual'],\n",
    "                                'classification_stop':hy_parameter['classification_stop']['actual'],\n",
    "                                'regression_stop':hy_parameter['regression_stop']['actual'],\n",
    "                                'score_validation_sampling':hy_parameter['score_validation_sampling']['actual'],                                          \n",
    "                                'overwrite_with_best_model':hy_parameter['overwrite_with_best_model']['actual'],\n",
    "                                'use_all_factor_levels':hy_parameter['use_all_factor_levels']['actual'],\n",
    "                                'standardize':hy_parameter['standardize']['actual'],\n",
    "                                'fast_mode':hy_parameter['fast_mode']['actual'],\n",
    "                                'variable_importances':hy_parameter['variable_importances']['actual'],                                          \n",
    "                                'fast_mode':hy_parameter['fast_mode']['actual'],\n",
    "                                'force_load_balance':hy_parameter['force_load_balance']['actual'],\n",
    "                                'replicate_training_data':hy_parameter['replicate_training_data']['actual'],\n",
    "                                'shuffle_training_data':hy_parameter['shuffle_training_data']['actual'],\n",
    "                                'missing_values_handling':hy_parameter['missing_values_handling']['actual'],\n",
    "                                'sparse':hy_parameter['sparse']['actual'],\n",
    "                                'col_major':hy_parameter['col_major']['actual'],\n",
    "                                'average_activation':hy_parameter['average_activation']['actual'],\n",
    "                                'sparsity_beta':hy_parameter['sparsity_beta']['actual'],                                          \n",
    "                                'max_categorical_features':hy_parameter['max_categorical_features']['actual'],\n",
    "                                'reproducible':hy_parameter['reproducible']['actual'],\n",
    "                                'elastic_averaging':hy_parameter['elastic_averaging']['actual'],\n",
    "                                'elastic_averaging_moving_rate':hy_parameter['elastic_averaging_moving_rate']['actual'],\n",
    "                                'elastic_averaging_regularization':hy_parameter['elastic_averaging_regularization']['actual'],\n",
    "                                'categorical_encoding':hy_parameter['categorical_encoding']['actual']\n",
    "                                         \n",
    "                                         },\n",
    "                             ignore_index=True)\n",
    "#     stackedensemble\n",
    "#     elif (mod_best1.algo == 'stackedensemble'):\n",
    "#         for models in stack_models(mod_best1):\n",
    "# #             print(mod_best1)\n",
    "# #             print(models)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gbm\n",
    "# df_gbm[['Model_name','Leaderboard_rank','RMSE_VAL','learn_rate','max_depth','sample_rate','col_sample_rate','ntrees','nfolds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Deeplearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_drf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM_Para= run_id + \"_GBM\" + '_hyperparameters.json' \n",
    "df_gbm.to_json(GBM_Para)\n",
    "\n",
    "GLM_Para= run_id + \"_GLM\" + '_hyperparameters.json' \n",
    "df_Deeplearn.to_json(GLM_Para)\n",
    "\n",
    "DRF_para= run_id + \"_DRF\" + '_hyperparameters.json' \n",
    "df_glm.to_json(DRF_para)\n",
    "\n",
    "Deeplearn_para= run_id + \"_Deeplearn\" + '_hyperparameters.json' \n",
    "df_drf.to_json(Deeplearn_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(5, 1, figsize=(20,25))\n",
    "\n",
    "ax1.plot(df_gbm['ntrees'],df_gbm['RMSE_VAL'],color='red', marker='o', linestyle='dashed',linewidth=2, markersize=12)\n",
    "ax1.set_title('ntrees vs RMSE')\n",
    "ax1.set_ylabel('RMSE')\n",
    "ax1.set_xlabel('ntrees')\n",
    "\n",
    "ax2.plot(df_gbm['max_depth'],df_gbm['RMSE_VAL'],color='red', marker='o', linestyle='dashed',linewidth=2, markersize=12)\n",
    "ax2.set_title('max_depth vs RMSE')\n",
    "ax2.set_ylabel('RMSE')\n",
    "ax2.set_xlabel('max_depth')\n",
    "\n",
    "ax3.plot(df_gbm['learn_rate'],df_gbm['RMSE_VAL'],color='blue', marker='o', linestyle='dashed',linewidth=2, markersize=12)\n",
    "ax3.set_title('learn_rate vs RMSE')\n",
    "ax3.set_ylabel('RMSE')\n",
    "ax3.set_xlabel('learn_rate')\n",
    "\n",
    "ax4.plot(df_gbm['sample_rate'],df_gbm['RMSE_VAL'],color='blue', marker='o', linestyle='dashed',linewidth=2, markersize=12)\n",
    "ax4.set_title('sample_rate vs RMSE')\n",
    "ax4.set_ylabel('RMSE')\n",
    "ax4.set_xlabel('sample_rate')\n",
    "\n",
    "ax5.plot(df_gbm['col_sample_rate'],df_gbm['RMSE_VAL'],color='blue', marker='o', linestyle='dashed',linewidth=2, markersize=12)\n",
    "ax5.set_title('col_sample_rate vs RMSE')\n",
    "ax5.set_ylabel('RMSE')\n",
    "ax5.set_xlabel('col_sample_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod_best_test=h2o.get_model(model_set[27])\n",
    "# print(mod_best_test.algo)\n",
    "# mod_best_test.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store_val=Variable_imp_list(h2o.get_model(model_set[1]))\n",
    "print(store_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_varimp = pd.DataFrame(store_val['varimp'])\n",
    "df_varimp.rename(columns={0:'Variable',1:'relative_importance',2:'scaled_importance',3:'percentage'}, inplace=True)\n",
    "df_varimp.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_varimp=df_varimp.sort_values(by=['relative_importance'],ascending=False)\n",
    "df_varimp['Variable'].head(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VarImp_Para= run_id + '__VariableImportance.json' \n",
    "df_varimp.to_json(VarImp_Para)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Evaluation Matric - RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_leaderboard_df=aml.leaderboard.as_data_frame()\n",
    "model_set=aml_leaderboard_df['model_id']\n",
    "mod_best1=h2o.get_model(model_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Model Name: \",mod_best.rmse())\n",
    "print(\"RMSE of best iteration: \",mod_best.rmse())\n",
    "print(\"RMSE on CV: \",mod_best.rmse(xval=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mod_best1.algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=run_id+'_metadata.json'\n",
    "dict_to_json(meta_data,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 2 : Increasing AutoML running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml2 = H2OAutoML(max_runtime_secs=777, seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_start_time = time.time()\n",
    "aml2.train(x=predictors, y=Target, training_frame=H2O_df)\n",
    "model_end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDT=datetime.datetime.now()\n",
    "currentDT=currentDT.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "predictors_list=' |'.join(predictors)\n",
    "\n",
    "meta_data={}\n",
    "meta_data['Problem type'] =\"classification\"\n",
    "meta_data['Target']='TARGET_deathRate'\n",
    "meta_data['predictors']=predictors_list\n",
    "meta_data['Execution_Date'] = currentDT\n",
    "meta_data['model_execution_time'] = {(model_end_time - model_start_time)}\n",
    "meta_data['max_runtime_secs']='777'\n",
    "meta_data['Evaluation_Matric']='RMSE'\n",
    "# meta_data=meta_data.as_data_frame()\n",
    "pd_meta=pd.DataFrame.from_dict(meta_data)\n",
    "\n",
    "# Save metadata\n",
    "pd_meta.to_json('C://Users//kaila//OneDrive//Desktop//DSMT//HYPERPARAMETER-Project//LeaderBoard//Iteration2_metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View the AutoML Leaderboard\n",
    "lb2 = aml2.leaderboard\n",
    "lb2.head(rows=lb2.nrows)  # Print all rows instead of default (10 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandaFrame2 = lb2.as_data_frame()\n",
    "# print(df_pandaFrame)\n",
    "df_pandaFrame2.to_json('C://Users//kaila//OneDrive//Desktop//DSMT//HYPERPARAMETER-Project//Iteration2_777.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_leaderboard_df2=aml2.leaderboard.as_data_frame()\n",
    "model_set2=aml_leaderboard_df2['model_id']\n",
    "mod_best2=h2o.get_model(model_set2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mod_best2.algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list2 = []\n",
    "for key, value in mod_best2.params.items():\n",
    "    params_list2.append(str(key)+\" = \"+str(value['actual']))\n",
    "params_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 3 : Increasing AutoML running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml3 = H2OAutoML(max_runtime_secs=999, seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    aml3.train(x=predictors, y=Target, training_frame=H2O_df)\n",
    "except Exception as e:\n",
    "    \n",
    "    logging.critical('aml3.train')\n",
    "    h2o.download_all_logs(dirname=logs_path, filename=logfile)\n",
    "    h2o.cluster().shutdown()\n",
    "    sys.exit(4)\n",
    "\n",
    "model_end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDT=datetime.datetime.now()\n",
    "currentDT=currentDT.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "predictors_list=' |'.join(predictors)\n",
    "\n",
    "meta_data={}\n",
    "meta_data['Problem type'] =\"classification\"\n",
    "meta_data['Target']='TARGET_deathRate'\n",
    "meta_data['predictors']=predictors_list\n",
    "meta_data['Execution_Date'] = currentDT\n",
    "meta_data['model_execution_time'] = {(model_end_time - model_start_time)}\n",
    "meta_data['max_runtime_secs']='999'\n",
    "meta_data['Evaluation_Matric']='RMSE'\n",
    "# meta_data=meta_data.as_data_frame()\n",
    "pd_meta=pd.DataFrame.from_dict(meta_data)\n",
    "\n",
    "# Save metadata\n",
    "pd_meta.to_json('C://Users//kaila//OneDrive//Desktop//DSMT//HYPERPARAMETER-Project//LeaderBoard//Iteration3_metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the AutoML Leaderboard\n",
    "lb3 = aml3.leaderboard\n",
    "lb3.head(rows=lb3.nrows)  # Print all rows instead of default (10 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandaFrame3 = lb3.as_data_frame()\n",
    "# print(df_pandaFrame)\n",
    "df_pandaFrame3.to_json('C://Users//kaila//OneDrive//Desktop//DSMT//HYPERPARAMETER-Project//Iteration3_999.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 4 : Increasing AutoML running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml4 = H2OAutoML(max_runtime_secs=1333, seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    aml4.train(x=predictors, y=Target, training_frame=H2O_df)\n",
    "except Exception as e:\n",
    "    \n",
    "    logging.critical('aml4.train')\n",
    "    h2o.download_all_logs(dirname=logs_path, filename=logfile)\n",
    "    h2o.cluster().shutdown()\n",
    "    sys.exit(4)\n",
    "\n",
    "model_end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDT=datetime.datetime.now()\n",
    "currentDT=currentDT.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "predictors_list=' |'.join(predictors)\n",
    "\n",
    "meta_data={}\n",
    "meta_data['Problem type'] =\"classification\"\n",
    "meta_data['Target']='TARGET_deathRate'\n",
    "meta_data['predictors']=predictors_list\n",
    "meta_data['Execution_Date'] = currentDT\n",
    "meta_data['model_execution_time'] = {(model_end_time - model_start_time)}\n",
    "meta_data['max_runtime_secs']='1333'\n",
    "meta_data['Evaluation_Matric']='RMSE'\n",
    "# meta_data=meta_data.as_data_frame()\n",
    "pd_meta=pd.DataFrame.from_dict(meta_data)\n",
    "\n",
    "# Save metadata\n",
    "pd_meta.to_json('C://Users//kaila//OneDrive//Desktop//DSMT//HYPERPARAMETER-Project//LeaderBoard//Iteration4_metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the AutoML Leaderboard\n",
    "lb4 = aml4.leaderboard\n",
    "lb4.head(rows=lb4.nrows)  # Print all rows instead of default (10 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandaFrame4 = lb4.as_data_frame()\n",
    "# print(df_pandaFrame)\n",
    "df_pandaFrame4.to_json('C://Users//kaila//OneDrive//Desktop//DSMT//HYPERPARAMETER-Project//Iteration4_1333.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - 5 : Increasing AutoML running timeÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml5 = H2OAutoML(max_runtime_secs=1555, seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    aml5.train(x=predictors, y=Target, training_frame=H2O_df)\n",
    "except Exception as e:\n",
    "    \n",
    "    logging.critical('aml5.train')\n",
    "    h2o.download_all_logs(dirname=logs_path, filename=logfile)\n",
    "    h2o.cluster().shutdown()\n",
    "    sys.exit(4)\n",
    "\n",
    "model_end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDT=datetime.datetime.now()\n",
    "currentDT=currentDT.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "predictors_list=' |'.join(predictors)\n",
    "\n",
    "meta_data={}\n",
    "meta_data['Problem type'] =\"classification\"\n",
    "meta_data['Target']='TARGET_deathRate'\n",
    "meta_data['predictors']=predictors_list\n",
    "meta_data['Execution_Date'] = currentDT\n",
    "meta_data['model_execution_time'] = {(model_end_time - model_start_time)}\n",
    "meta_data['max_runtime_secs']='1555'\n",
    "meta_data['Evaluation_Matric']='RMSE'\n",
    "# meta_data=meta_data.as_data_frame()\n",
    "pd_meta=pd.DataFrame.from_dict(meta_data)\n",
    "\n",
    "# Save metadata\n",
    "pd_meta.to_json('C://Users//kaila//OneDrive//Desktop//DSMT//HYPERPARAMETER-Project//LeaderBoard//Iteration5_metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the AutoML Leaderboard\n",
    "lb5 = aml5.leaderboard\n",
    "lb5.head(rows=lb5.nrows)  # Print all rows instead of default (10 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandaFrame5 = lb5.as_data_frame()\n",
    "# print(df_pandaFrame)\n",
    "df_pandaFrame5.to_json('C://Users//kaila//OneDrive//Desktop//DSMT//HYPERPARAMETER-Project//Iteration5_1555.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['I', 'am', 'Pyhton', 'prog']\n",
    "\n",
    "S1: s = \"\"\n",
    "    for x in lst:\n",
    "        s+=x\n",
    "        \n",
    "S2: s= \"\".join(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully implementation various regression algorithms like linear Regression, Logistic regression, StepWise Regression and Ridge regression (i.e _L2 regularization_) to predict Cancer Mortality Rates for US Counties. <br />\n",
    "Cancer Mortality Rates for US Counties is depend upon various factors like <br /> TARGET_deathRate,incidenceRate,medIncome,povertyPercent,PctHS25_Over,PctEmployed16_Over,PctUnemployed16_Over, <br /> PctPrivateCoverage,PctPrivateCoverageAlone,PctPublicCoverage,PctPublicCoverageAlone <br />\n",
    "but the most prominent are : <br />\n",
    "incidenceRate, PctPrivateCoverage, PctHS25_Over, povertyPercent, PctUnemployed16_Over, PctPrivateCoverageAlone, <br /> PctEmployed16_Over, PctPublicCoverage, PctPublicCoverageAlone, medIncome <br />\n",
    "\n",
    "In linear regression The best model give the 'best fit'(R-Square) of: 0.51 while in Logistic Rgression's the best model gives accuracy of 0.97.\n",
    "In our analysis the predictors we use in linear Regression and predictors suggested by forward stepwise regression are same wich suggest that the independent variable we use are very correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above analysis:\n",
    "- 70% of explanation, analysis and code is done by me.\n",
    "- 20% of resource is from web and citations are given below.\n",
    "- 10% of resource is from prof. Nik Brown notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset : https://data.world/nrippner/ols-regression-challenge <br />\n",
    "Regression methods : https://github.com/nikbearbrown/INFO_6105/<br />\n",
    "Learn ROC Curve : https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8 <br />\n",
    "Dummy function : https://towardsdatascience.com/the-dummys-guide-to-creating-dummy-variables-f21faddb1d40 <br />\n",
    "K-fold cross validation: https://towardsdatascience.com/cross-validation-70289113a072 <br />\n",
    "Homoscedasticity : http://davidmlane.com/hyperstat/A121947.html <br />\n",
    "Confusion Matrix : https://stackoverflow.com/questions/30746460/how-to-interpret-scikits-learn-confusion-matrix-and-classification-report <br />\n",
    "Forward Stepwise : https://planspace.org/20150423-forward_selection_with_statsmodels/ <br />\n",
    "Backword Elimination : https://www.kaggle.com/umeshsati54/backward-elimination <br />\n",
    "Feature Scalling : http://sebastianraschka.com/Articles/2014_about_feature_scaling.html#about-standardization <br />\n",
    "Outliers : https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba <br />\n",
    "Standard Error : http://changingminds.org/explanations/research/statistics/standard_error.htm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright 2019 Kailash Nadkar\n",
    "\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
